{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MNIST with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8192\n",
    "validation_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True,transform=torchvision.transforms.ToTensor())\n",
    "mnist_trainset,mnist_valset = torch.utils.data.random_split(mnist_trainset, [len(mnist_trainset)-10000,10000])\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True,transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7fd7b91b5820>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd7a0c35b80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist_trainset[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    mnist_trainset,\n",
    "    num_workers=2,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    mnist_valset,\n",
    "    num_workers=2,\n",
    "    batch_size=len(mnist_valset),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx, (example_data, example_targets) = next(enumerate(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-47f6a1d00e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not an iterator"
     ]
    }
   ],
   "source": [
    "next(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2,padding=0)\n",
    "        self.linear1 = nn.Linear(13*13*20,100) \n",
    "        self.linear2 = nn.Linear(100,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.linear1(x.view(-1,13*13*20))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(example_data[0:4]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-3,momentum=0.9)\n",
    "loss_func = nn.CrossEntropyLoss() \n",
    "epochs = 10\n",
    "val_frequency = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using CrossEntropyLoss() it did the softmax so ne need to add it in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs,model,loader,val_loader,optimizer,loss_func,val_frequency):\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, targets) in enumerate(loader):\n",
    "            optimizer.zero_grad()\n",
    "            data.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_func(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch == 0 or epoch%val_frequency == 0 or epoch == epochs-1):\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                _,(val_data, val_targets) = next(enumerate(train_loader))\n",
    "                val_data.to(device)\n",
    "                output_val = model(val_data)\n",
    "                loss_val = loss_func(output_val, val_targets)\n",
    "\n",
    "            print(f\"Epoch {epoch}, loss_train {loss.item()}, loss_val {loss_val.item()}\")\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss_train 0.5513596534729004, loss_val 0.543336808681488\n",
      "Epoch 2, loss_train 0.5245392918586731, loss_val 0.530299186706543\n",
      "Epoch 4, loss_train 0.5217263102531433, loss_val 0.5027945041656494\n",
      "Epoch 6, loss_train 0.4413565993309021, loss_val 0.4917885959148407\n",
      "Epoch 8, loss_train 0.5155934691429138, loss_val 0.4816036820411682\n",
      "Epoch 9, loss_train 0.4727356731891632, loss_val 0.4766820967197418\n"
     ]
    }
   ],
   "source": [
    "train(epochs,model,train_loader,val_loader,optimizer,loss_func,val_frequency)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
