{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # MNIST with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size = 8192\n",
    "batch_size = 8192\n",
    "validation_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I onyl have 2gb of VRAM so i am using a smaller batch_size to fit the data in the VRAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(0, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will normalize the data so that it means is zero and it variance 1 because i don't find how to fit my data to [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True,transform=transforms)\n",
    "mnist_trainset,mnist_valset = torch.utils.data.random_split(mnist_trainset, [len(mnist_trainset)-10000,10000])\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True,transform=transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x7f5ef01d9040>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5ed532a550>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist_trainset[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    mnist_trainset,\n",
    "    num_workers=2,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    mnist_valset,\n",
    "    num_workers=2,\n",
    "    batch_size=len(mnist_valset),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    mnist_testset,\n",
    "    num_workers=2,\n",
    "    batch_size=len(mnist_testset),\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx, (example_data, example_targets) = next(enumerate(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self,_midel_layer):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(28*28,50) \n",
    "        nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        \n",
    "        self.linear2 = nn.Linear(50,2)\n",
    "        nn.init.xavier_uniform_(self.linear2.weight)\n",
    "        \n",
    "        self.linear3 = nn.Linear(2,28*28)\n",
    "        nn.init.xavier_uniform_(self.linear3.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        original_shape = x.shape\n",
    "        x = x.view(-1,28*28)\n",
    "        x = self.linear1(F.relu(x))\n",
    "        x = self.linear2(F.relu(x))\n",
    "        x = self.linear3(F.relu(x))\n",
    "    \n",
    "        x = x.view(original_shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model1(\n",
       "  (linear1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (linear2): Linear(in_features=50, out_features=2, bias=True)\n",
       "  (linear3): Linear(in_features=2, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model1()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_train = []\n",
    "losses_val = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss_train 0.28267911076545715, loss_val 0.28006964921951294\n",
      "Epoch 1, loss_train 0.2770865857601166, loss_val 0.27930527925491333\n",
      "Epoch 2, loss_train 0.27998092770576477, loss_val 0.2784222662448883\n",
      "Epoch 3, loss_train 0.27818337082862854, loss_val 0.2773968577384949\n",
      "Epoch 4, loss_train 0.2758939862251282, loss_val 0.27621063590049744\n",
      "Epoch 5, loss_train 0.2738405168056488, loss_val 0.27477216720581055\n",
      "Epoch 6, loss_train 0.2729851007461548, loss_val 0.27301692962646484\n",
      "Epoch 7, loss_train 0.271473228931427, loss_val 0.271008163690567\n",
      "Epoch 8, loss_train 0.2678741216659546, loss_val 0.2687607705593109\n",
      "Epoch 9, loss_train 0.2651645839214325, loss_val 0.2663060426712036\n",
      "CPU times: user 1.6 s, sys: 961 ms, total: 2.56 s\n",
      "Wall time: 36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 10\n",
    "val_frequency = 1\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data = data.to(device)\n",
    "        output = model(data)\n",
    "        loss = loss_func(output, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch == 0 or epoch%val_frequency == 0 or epoch == epochs-1):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _,(val_data, _) = next(enumerate(val_loader))\n",
    "            val_data = val_data.to(device)\n",
    "            output_val = model(val_data)\n",
    "            loss_val = loss_func(output_val, val_data)\n",
    "        losses_train.append(loss.item())\n",
    "        losses_val.append(loss_val.item())\n",
    "        print(f\"Epoch {epoch}, loss_train {loss.item()}, loss_val {loss_val.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses_train,color=\"blue\",label=\"train\")\n",
    "plt.plot(losses_val,color=\"orange\",label=\"val\")  \n",
    "plt.title(\"Error evolution throw training\")\n",
    "plt.ylabel(\"Loss function\")\n",
    "plt.xlabel(f\"{val_frequency}-Epochs\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "\n",
    "print(f\"Total epoch : {(len(losses_train)-1)*val_frequency}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (test_data, test_targets) = next(enumerate(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "score(test_data,model,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'losses_train': losses_train,\n",
    "            'losses_val': losses_val\n",
    "            }, \"model/model_autoencoder.m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
